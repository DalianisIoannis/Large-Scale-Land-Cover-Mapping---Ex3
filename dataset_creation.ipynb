{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read labels json and print all unique ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ελέγξτε πόσες και ποιες κατηγορίες είναι διαθέσιμες στο υποσύνολο δεδομένων της άσκησης. Ορίστε νέο indexing για τις κατηγορίες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "import random\n",
    "import zarr\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "\n",
    "# labels of zarr files according to labels.json\n",
    "f_labels = open(r\"Exercise4\\timematch_data\\denmark\\32VNH\\2017\\meta\\labels.json\")\n",
    "labels_json_original = json.load(f_labels)\n",
    "\n",
    "print(len(labels_json_original.keys()))\n",
    "print(len(set(labels_json_original.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Οι διαθέσιμες  κατηγορίες στα δικά μας αρχικά δεδομένα είναι 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spring_barley 1141\n",
      "winter_rye 317\n",
      "spring_peas 17\n",
      "winter_barley 352\n",
      "horsebeans 28\n",
      "spring_wheat 26\n",
      "winter_wheat 856\n",
      "winter_rapeseed 301\n",
      "unknown 511\n",
      "winter_triticale 42\n",
      "corn 275\n",
      "spring_triticale 2\n",
      "spring_oat 120\n",
      "meadow 1013\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "for val in labels_json_original.values():\n",
    "    unique_labels.add(val)\n",
    "\n",
    "labels_counter = Counter(labels_json_original.values())\n",
    "\n",
    "for lab in unique_labels:\n",
    "    print(lab, labels_counter[lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τα δεδομένα κατηγοριών με λιγότερα από 200 δείγματα φεύγουν"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "def move_zarr_files_based_on_label(label_occurrences, zarr_folder_path, json_file_path, destination_folder_path):\n",
    "    # Load the JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        labels = json.load(json_file)\n",
    "    \n",
    "    # Ensure the destination folder exists\n",
    "    os.makedirs(destination_folder_path, exist_ok=True)\n",
    "\n",
    "    # Iterate over the zarr files in the given folder\n",
    "    for file_name in os.listdir(zarr_folder_path):\n",
    "        if file_name.endswith('.zarr'):\n",
    "            file_number = file_name.replace('.zarr', '')\n",
    "            \n",
    "            # Check if the file number is in the labels dictionary\n",
    "            if file_number in labels:\n",
    "                label = labels[file_number]\n",
    "                \n",
    "                # Check if the occurrence of the label is less than 200\n",
    "                if label_occurrences.get(label, 0) < 200:\n",
    "                    source_path = os.path.join(zarr_folder_path, file_name)\n",
    "                    destination_path = os.path.join(destination_folder_path, file_name)\n",
    "                    \n",
    "                    shutil.move(source_path, destination_path)\n",
    "                    print(f\"Moved {file_name} to {destination_folder_path}\")\n",
    "\n",
    "# move_zarr_files_based_on_label(\n",
    "#     labels_counter,\n",
    "#     \"Exercise4/timematch_data/denmark/32VNH/2017/data\",\n",
    "#     r\"C:\\Users\\Yannis\\Downloads\\edemm_earino\\gewxwrika\\proj3\\Exercise4\\timematch_data\\denmark\\32VNH\\2017\\meta\\labels.json\",\n",
    "#     \"moved_zarrs\")\n",
    "\n",
    "print(len(os.listdir(\"moved_zarrs\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Φεύγουν και τα δείγματα άγνωστων κατηγοριών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n"
     ]
    }
   ],
   "source": [
    "def move_unknown_zarr(zarr_folder_path, json_file_path, destination_folder_path):\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        labels = json.load(json_file)\n",
    "    \n",
    "    os.makedirs(destination_folder_path, exist_ok=True)\n",
    "\n",
    "    # Iterate over the zarr files in the given folder\n",
    "    for file_name in os.listdir(zarr_folder_path):\n",
    "        if file_name.endswith('.zarr'):\n",
    "            file_number = file_name.replace('.zarr', '')\n",
    "\n",
    "            # Check if the file number is in the labels dictionary\n",
    "            if file_number in labels:\n",
    "                label = labels[file_number]\n",
    "\n",
    "                if label == 'unknown':\n",
    "                    source_path = os.path.join(zarr_folder_path, file_name)\n",
    "                    destination_path = os.path.join(destination_folder_path, file_name)\n",
    "                    \n",
    "                    shutil.move(source_path, destination_path)\n",
    "                    print(f\"Moved {file_name} to {destination_folder_path}\")\n",
    "\n",
    "# move_unknown_zarr(\n",
    "#     \"Exercise4/timematch_data/denmark/32VNH/2017/data\",\n",
    "#     r\"C:\\Users\\Yannis\\Downloads\\edemm_earino\\gewxwrika\\proj3\\Exercise4\\timematch_data\\denmark\\32VNH\\2017\\meta\\labels.json\",\n",
    "#     \"moved_unknowns\")\n",
    "\n",
    "print(len(os.listdir(\"moved_unknowns\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Καινούριο dict από labels με τα δείγματα που έχουν απομείνει"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4255\n",
      "0 corn\n",
      "1 corn\n",
      "10 corn\n",
      "100 winter_rapeseed\n",
      "1000 spring_barley\n",
      "1001 winter_rye\n",
      "1002 spring_barley\n",
      "\n",
      "corn 275\n",
      "winter_rapeseed 301\n",
      "spring_barley 1141\n",
      "winter_rye 317\n",
      "winter_barley 352\n",
      "winter_wheat 856\n",
      "meadow 1013\n"
     ]
    }
   ],
   "source": [
    "# labels_200 will contain the labels with more than 200 occurrences\n",
    "labels_200 = {}\n",
    "\n",
    "for file_name in os.listdir(\"Exercise4/timematch_data/denmark/32VNH/2017/data\"):\n",
    "    if file_name.endswith('.zarr'):\n",
    "        file_number = file_name.replace('.zarr', '')\n",
    "        # print(file_number)\n",
    "        \n",
    "        # if the number of occurrences of label is greater than 200,\n",
    "        # add it to the labels_200 dictionary\n",
    "        # print(labels_counter[file_number])\n",
    "        category = labels_json_original[file_number]\n",
    "        if labels_counter[category] > 200:\n",
    "            labels_200[file_number] = labels_json_original[file_number]\n",
    "            # labels_200[int(file_number)] = labels_json_original[file_number]\n",
    "\n",
    "# labels_200 = dict(sorted(labels_200.items()))\n",
    "print(len(labels_200))\n",
    "\n",
    "count = 0\n",
    "for lab in labels_200:\n",
    "    print(lab, labels_200[lab])\n",
    "    count += 1\n",
    "    if count == 7:\n",
    "        break\n",
    "\n",
    "labels_200_counter = Counter(labels_200.values())\n",
    "\n",
    "print()\n",
    "\n",
    "for lab in labels_200_counter:\n",
    "    print(lab, labels_200_counter[lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αντιστοίχιση τελικών labels με αριθμητικά indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corn 0\n",
      "winter_rapeseed 1\n",
      "spring_barley 2\n",
      "winter_rye 3\n",
      "winter_barley 4\n",
      "winter_wheat 5\n",
      "meadow 6\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = {cls: idx for idx, cls in enumerate(labels_200_counter)}\n",
    "\n",
    "for key, val in class_to_idx.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "\n",
    "class RandomSamplePixels(object):\n",
    "    \"\"\"Randomly draw num_pixels from the available pixels in sample.\n",
    "    If the total number of pixels is less than num_pixels, one arbitrary pixel is repeated.\n",
    "    The valid_pixels keeps track of true and repeated pixels.\n",
    "\n",
    "    Args:\n",
    "        num_pixels (int): Number of pixels to sample.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels):\n",
    "        self.num_pixels = num_pixels\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        pixels = sample['pixels']\n",
    "        \n",
    "        T, C, S = pixels.shape\n",
    "        if S > self.num_pixels:\n",
    "            indices = random.sample(range(S), self.num_pixels)\n",
    "            x = pixels[:, :, indices]\n",
    "            valid_pixels = np.ones(self.num_pixels)\n",
    "        elif S < self.num_pixels:\n",
    "            x = np.zeros((T, C, self.num_pixels))\n",
    "            x[..., :S] = pixels\n",
    "            x[..., S:] = np.stack([x[:, :, 0] for _ in range(S, self.num_pixels)], axis=-1)\n",
    "            valid_pixels = np.array([1 for _ in range(S)] + [0 for _ in range(S, self.num_pixels)])\n",
    "        else:\n",
    "            x = pixels\n",
    "            valid_pixels = np.ones(self.num_pixels)\n",
    "        # Repeat valid_pixels across time\n",
    "        valid_pixels = np.repeat(valid_pixels[np.newaxis].astype(np.float32), x.shape[0], axis=0)\n",
    "        sample['pixels'] = x\n",
    "        sample['valid_pixels'] = valid_pixels\n",
    "        return sample\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize by rescaling pixels to [0, 1]\n",
    "\n",
    "    Args:\n",
    "        max_pixel_value (int): Max value of pixels to move pixels to [0, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_pixel_value=65535):\n",
    "        self.max_pixel_value = max_pixel_value\n",
    "\n",
    "        # approximate max values\n",
    "        max_parcel_box_m = 10000\n",
    "        max_perimeter = max_parcel_box_m * 4\n",
    "        max_area = max_parcel_box_m ** 2\n",
    "        max_perimeter_area_ratio = max_perimeter\n",
    "        max_cover_ratio = 1.0\n",
    "        self.max_extra_values = np.array([max_perimeter, max_area, max_perimeter_area_ratio, max_cover_ratio])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['pixels'] = np.clip(sample['pixels'], 0, self.max_pixel_value).astype(np.float32) / self.max_pixel_value\n",
    "        \n",
    "        # if 'extra' in sample:\n",
    "        #     sample['extra'] = sample['extra'].astype(np.float32) / self.max_extra_values\n",
    "        \n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        sample['pixels'] = torch.from_numpy(sample['pixels'].astype(np.float32))\n",
    "        sample['valid_pixels'] = torch.from_numpy(sample['valid_pixels'].astype(np.float32))\n",
    "        # sample['positions'] = torch.from_numpy(sample['positions'].astype(np.long))\n",
    "        # if 'extra' in sample:\n",
    "        #     sample['extra'] = torch.from_numpy(sample['extra'].astype(np.float32))\n",
    "        if isinstance(sample['label'], int):\n",
    "            sample['label'] = torch.tensor(sample['label']).long()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ix(dct, n):\n",
    "#     # get nth key of a dictionary\n",
    "#     return list(dct)[n]\n",
    "   \n",
    "class PixelSetData(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_root,\n",
    "            class_to_idx,\n",
    "            true_labels,\n",
    "            # num_pixels = 32,\n",
    "            transform=None,\n",
    "            ):\n",
    "\n",
    "        self.folder = os.path.join(data_root)\n",
    "        self.data_folder = os.path.join(self.folder, \"data\")\n",
    "        # self.meta_folder = os.path.join(self.folder, \"meta\")\n",
    "        self.data_labels = true_labels\n",
    "        # self.num_pixels = num_pixels\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = class_to_idx\n",
    "        # self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "        for i in range(10):\n",
    "            print(self.samples[i])\n",
    "    \n",
    "    # def __getitem__(self, index):\n",
    "    #     item = self.samples[index]\n",
    "    #     zarr_arr = zarr.load(item[0])\n",
    "    #     T, C, S = zarr_arr.shape\n",
    "    #     # return 32 random pixels\n",
    "    #     if S > self.num_pixels:\n",
    "    #         indices = random.sample(range(S), self.num_pixels)\n",
    "    #         x = zarr_arr[:, :, indices]\n",
    "    #     elif S < self.num_pixels:\n",
    "    #         x = np.zeros((T, C, self.num_pixels))\n",
    "    #         x[..., :S] = zarr_arr\n",
    "    #         x[..., S:] = np.stack([x[:, :, 0] for _ in range(S, self.num_pixels)], axis=-1)\n",
    "    #     else:\n",
    "    #         x = zarr_arr\n",
    "    #     return x\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, parcel_idx, y = self.samples[index]\n",
    "        pixels = zarr.load(path)  # (T, C, S)\n",
    "\n",
    "        sample = {\n",
    "            \"index\": index,\n",
    "            \"parcel_index\": parcel_idx,  # mapping to metadata\n",
    "            \"pixels\": pixels,\n",
    "            \"valid_pixels\": np.ones(\n",
    "                (pixels.shape[0], pixels.shape[-1]), dtype=np.float32),\n",
    "            # \"positions\": np.array(self.date_positions),\n",
    "            # \"extra\": np.array(extra),\n",
    "            \"label\": y,\n",
    "        }\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def _make_dataset(self):\n",
    "        # metadata = pkl.load(open(os.path.join(self.meta_folder, \"metadata.pkl\"), \"rb\"))\n",
    "        instances = []\n",
    "        \n",
    "        for zarr_file in os.listdir(self.data_folder):\n",
    "            if zarr_file.endswith(\".zarr\"):\n",
    "\n",
    "                zarr_idx = zarr_file.split(\".\")[-2]\n",
    "                parcel_path = os.path.join(self.data_folder, f\"{zarr_idx}.zarr\")\n",
    "                class_name = self.data_labels[zarr_idx]\n",
    "                item = (parcel_path, zarr_idx, class_name)\n",
    "                instances.append(item)\n",
    "        \n",
    "        return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\0.zarr', '0', 'corn')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1.zarr', '1', 'corn')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\10.zarr', '10', 'corn')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\100.zarr', '100', 'winter_rapeseed')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1000.zarr', '1000', 'spring_barley')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1001.zarr', '1001', 'winter_rye')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1002.zarr', '1002', 'spring_barley')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1003.zarr', '1003', 'winter_barley')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1004.zarr', '1004', 'winter_rapeseed')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1005.zarr', '1005', 'winter_rapeseed')\n",
      "\n",
      "4255\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        RandomSamplePixels(32),\n",
    "        Normalize(),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "pixel_dataset = PixelSetData(\"Exercise4/timematch_data/denmark/32VNH/2017\",\n",
    "                             class_to_idx,\n",
    "                             labels_200,\n",
    "                             train_transform)\n",
    "print()\n",
    "print(len(pixel_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index <class 'int'> 10\n",
      "parcel_index <class 'str'> 1006\n",
      "pixels <class 'torch.Tensor'> torch.Size([52, 10, 32])\n",
      "valid_pixels <class 'torch.Tensor'> torch.Size([52, 32])\n",
      "label <class 'str'> winter_wheat\n"
     ]
    }
   ],
   "source": [
    "ret = pixel_dataset[10]\n",
    "\n",
    "for k, v in ret.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(k, type(v), v.shape)\n",
    "    else:\n",
    "        print(k, type(v), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index <class 'int'> 1901\n",
      "parcel_index <class 'str'> 2999\n",
      "pixels <class 'torch.Tensor'> torch.Size([52, 10, 32])\n",
      "valid_pixels <class 'torch.Tensor'> torch.Size([52, 32])\n",
      "label <class 'str'> winter_wheat\n"
     ]
    }
   ],
   "source": [
    "ret = pixel_dataset[1901]\n",
    "\n",
    "for k, v in ret.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(k, type(v), v.shape)\n",
    "    else:\n",
    "        print(k, type(v), v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

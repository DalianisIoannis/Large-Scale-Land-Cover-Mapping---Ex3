{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code comes from https://github.com/jnyborg/timematch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from torchvision.transforms import transforms\n",
    "from utils import RandomSamplePixels, Normalize, ToTensor, PixelSetData,\\\n",
    "    split_dict_train_test, pad_sequences_collate_fn, LinearLayer, PixelSetEncoder,\\\n",
    "        PositionalEncoding, TimeSeriesTransformer, SimpleMLP\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([52, 32, 10])\n",
      "torch.Size([52, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "# pixels_tmp = pixel_dataset[1901]['pixels'].permute(0, 2, 1)\n",
    "pixels_tmp = torch.randn(52, 10, 32).permute(0, 2, 1)\n",
    "print(\"input\", pixels_tmp.shape)\n",
    "\n",
    "ll = LinearLayer(10, 64)\n",
    "\n",
    "print(ll(pixels_tmp).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δοκιμή του LinearLayer με τυχαία διανύσματα όμως ΧΩΡΙΣ μάσκες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LinearLayer(\n",
      "    (linear): Linear(in_features=10, out_features=32, bias=False)\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): LinearLayer(\n",
      "    (linear): Linear(in_features=64, out_features=128, bias=False)\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 52, 10, 32])\n",
      "torch.Size([52, 32, 10])\n",
      "torch.Size([52, 32, 32])\n",
      "torch.Size([52, 64])\n",
      "torch.Size([52, 128])\n",
      "torch.Size([1, 52, 128])\n"
     ]
    }
   ],
   "source": [
    "# mlp1_dim=[10, 32, 64]\n",
    "mlp1_dim=[10, 32]\n",
    "mlp2_dim=[64, 128]\n",
    "\n",
    "layers = []\n",
    "for i in range(len(mlp1_dim) - 1):\n",
    "    layers.append(LinearLayer(mlp1_dim[i], mlp1_dim[i + 1]))\n",
    "mlp1 = nn.Sequential(*layers)\n",
    "print(mlp1)\n",
    "\n",
    "layers = []\n",
    "for i in range(len(mlp2_dim) - 1):\n",
    "    layers.append(LinearLayer(mlp2_dim[i], mlp2_dim[i + 1]))\n",
    "mlp2 = nn.Sequential(*layers)\n",
    "print(mlp2)\n",
    "\n",
    "# out = pixel_dataset[1901]['pixels'].unsqueeze(0)\n",
    "out = torch.randn(52, 10, 32).unsqueeze(0)\n",
    "print(out.shape) # torch.Size([1, 52, 10, 32])\n",
    "\n",
    "batch, temp = out.shape[:2]\n",
    "# print(batch, temp) # 1 52\n",
    "\n",
    "out = out.view(batch * temp, *out.shape[2:]).transpose(1, 2)  # (B*T, S, C)\n",
    "print(out.shape) # torch.Size([52, 32, 10])\n",
    "\n",
    "out = mlp1(out).transpose(1, 2)\n",
    "print(out.shape) # torch.Size([52, 32, 32])\n",
    "\n",
    "out = torch.cat(\n",
    "            [out.mean(dim=-1), out.std(dim=-1)],\n",
    "            dim=1)\n",
    "print(out.shape) # torch.Size([52, 64])\n",
    "\n",
    "out = mlp2(out)\n",
    "print(out.shape) # torch.Size([52, 128])\n",
    "\n",
    "out = out.view(batch, temp, -1)\n",
    "print(out.shape) # torch.Size([1, 52, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSE Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Οι extra χωρικές πληροφορίες δε χρειάζονται"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Είσοδος και έξοδος PSE πριν προστεθεί η μάσκα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input = pixel_dataset[1911]['pixels'].unsqueeze(0)\n",
    "# input = torch.randn(52, 10, 32).unsqueeze(0)\n",
    "# print(input.shape)\n",
    "# out = pixel_set_encoder(input)\n",
    "# print(out.shape) # torch.Size([1, 52, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δημιουργία Dataset και Dataloaders για τη δοκιμή του PSE και του Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4255 7\n",
      "0 corn\n",
      "1 corn\n",
      "2 corn\n",
      "3 corn\n",
      "4 corn\n",
      "5 spring_barley\n",
      "\n",
      "corn 275\n",
      "spring_barley 1141\n",
      "meadow 1013\n",
      "winter_wheat 856\n",
      "winter_rapeseed 301\n",
      "winter_barley 352\n",
      "winter_rye 317\n"
     ]
    }
   ],
   "source": [
    "# labels_200 will contain the labels with more than 200 occurrences\n",
    "f_labels = open(r\"Exercise4\\timematch_data\\denmark\\32VNH\\2017\\meta\\labels_cleaned.json\")\n",
    "labels_200 = json.load(f_labels)\n",
    "\n",
    "print(len(labels_200), len(set(labels_200.values())))\n",
    "\n",
    "count = 0\n",
    "for lab in labels_200:\n",
    "    print(lab, labels_200[lab])\n",
    "    count += 1\n",
    "    if count == 6:\n",
    "        break\n",
    "\n",
    "labels_200_counter = Counter(labels_200.values())\n",
    "\n",
    "print()\n",
    "\n",
    "for lab in labels_200_counter:\n",
    "    print(lab, labels_200_counter[lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Οι παρακάτω αντιστοιχίσεις είναι διαφορετικές από του dataset_creation αλλά δεν πειράζει"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corn 0\n",
      "spring_barley 1\n",
      "meadow 2\n",
      "winter_wheat 3\n",
      "winter_rapeseed 4\n",
      "winter_barley 5\n",
      "winter_rye 6\n",
      "\n",
      "4255\n",
      "3400\n",
      "855\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = {cls: idx for idx, cls in enumerate(labels_200_counter)}\n",
    "for key, val in class_to_idx.items():\n",
    "    print(key, val)\n",
    "\n",
    "print()\n",
    "\n",
    "train_labels, val_labels = split_dict_train_test(labels_200, test_size=0.2)\n",
    "\n",
    "print(len(labels_200))\n",
    "print(len(train_labels))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\0.zarr', '0', 'corn')"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1.zarr', '1', 'corn')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\10.zarr', '10', 'corn')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\100.zarr', '100', 'winter_rapeseed')\n",
      "3400\n",
      "\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1003.zarr', '1003', 'winter_barley')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1009.zarr', '1009', 'winter_barley')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1014.zarr', '1014', 'meadow')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1017.zarr', '1017', 'meadow')\n",
      "855\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([RandomSamplePixels(32), Normalize(), ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([Normalize(), ToTensor()])\n",
    "\n",
    "train_dataset = PixelSetData(\"Exercise4/timematch_data/denmark/32VNH/2017\",\n",
    "                             class_to_idx, train_labels,\n",
    "                             train_transform)\n",
    "print(len(train_dataset))\n",
    "print()\n",
    "val_dataset = PixelSetData(\"Exercise4/timematch_data/denmark/32VNH/2017\",\n",
    "                             class_to_idx, val_labels,\n",
    "                             test_transform)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "107\n",
      "torch.Size([8, 52, 10, 32])\n",
      "torch.Size([8])\n",
      "tensor([6, 0, 1, 4, 1, 1, 5, 1])\n",
      "torch.Size([8, 52, 32])\n",
      "[ True]\n",
      "\n",
      "torch.Size([8, 52, 10, 2872])\n",
      "torch.Size([8])\n",
      "tensor([1, 5, 2, 2, 2, 1, 1, 4])\n",
      "torch.Size([8, 52, 2872])\n",
      "[False  True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dloader = DataLoader(\n",
    "    train_dataset, batch_size=8, shuffle=True,\n",
    "    collate_fn=pad_sequences_collate_fn,\n",
    "    # num_workers=4,\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dataset, batch_size=8, shuffle=True,\n",
    "    collate_fn=pad_sequences_collate_fn,\n",
    ")\n",
    "\n",
    "print(len(train_dloader))\n",
    "print(len(val_dloader))\n",
    "\n",
    "for batch in train_dloader:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    print(batch[1])\n",
    "    print(batch[2].shape)\n",
    "    print(np.unique(batch[2]))\n",
    "    print()\n",
    "    break\n",
    "\n",
    "for batch in val_dloader:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    print(batch[1])\n",
    "    print(batch[2].shape)\n",
    "    print(np.unique(batch[2]))\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PixelSetEncoder(\n",
      "  (mlp1): Sequential(\n",
      "    (0): LinearLayer(\n",
      "      (linear): Linear(in_features=10, out_features=32, bias=False)\n",
      "      (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mlp2): Sequential(\n",
      "    (0): LinearLayer(\n",
      "      (linear): Linear(in_features=64, out_features=128, bias=False)\n",
      "      (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "torch.Size([8, 52, 10, 32])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 52, 32])\n",
      "\n",
      "torch.Size([8, 52, 128])\n",
      "\n",
      "[0.0000000e+00 2.9236078e-05 3.0653551e-05 ... 5.7846966e+00 6.2438588e+00\n",
      " 6.3338661e+00]\n"
     ]
    }
   ],
   "source": [
    "pixel_set_encoder = PixelSetEncoder(10, mlp1=[10, 32],\n",
    "                                    pooling=\"mean_std\",\n",
    "                                    mlp2=[64, 128])\n",
    "print(pixel_set_encoder)\n",
    "print()\n",
    "\n",
    "for batch in train_dloader:\n",
    "    input_tensor = batch[0]\n",
    "    labels = batch[1]\n",
    "    mask = batch[2]\n",
    "\n",
    "    print(input_tensor.shape)\n",
    "    print(labels.shape)\n",
    "    print(mask.shape)\n",
    "\n",
    "    break\n",
    "\n",
    "print()\n",
    "\n",
    "out = pixel_set_encoder(input_tensor, mask)\n",
    "print(out.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(np.unique(out.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without collate_fn=pad_sequences_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dloader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=8,\n",
    "#     shuffle=True,\n",
    "#     # collate_fn=pad_sequences_collate_fn,\n",
    "#     # num_workers=4,\n",
    "# )\n",
    "\n",
    "# print(len(train_dloader))\n",
    "\n",
    "# for batch in train_dloader:\n",
    "#     input_tensor = batch[\"pixels\"]\n",
    "#     labels = batch[\"label_idx\"]\n",
    "#     mask = batch[\"valid_pixels\"]\n",
    "\n",
    "#     print(input_tensor.shape)\n",
    "#     print(labels.shape)\n",
    "#     print(labels)\n",
    "#     print(mask.shape)\n",
    "#     print()\n",
    "\n",
    "#     break\n",
    "\n",
    "# out = pixel_set_encoder(input_tensor, mask)\n",
    "\n",
    "# print(out.shape)\n",
    "\n",
    "# print(np.unique(out.detach().numpy()))\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PositionalEncoding()\n",
      "torch.Size([1, 52, 128])\n"
     ]
    }
   ],
   "source": [
    "# can also check Tsironis\n",
    "pe = PositionalEncoding(128)\n",
    "\n",
    "input = torch.randn(1, 52, 128)\n",
    "out = pe(input)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesTransformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pos_emb): PositionalEncoding()\n",
      ")\n",
      "Output shape:  torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# time_series_transformer = TimeSeriesTransformer(feature_size=128)\n",
    "time_series_transformer = TimeSeriesTransformer(d_model=128)\n",
    "print(time_series_transformer)\n",
    "\n",
    "input = torch.randn(1, 52, 128)\n",
    "out = time_series_transformer(input)\n",
    "print(\"Output shape: \", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 7])\n",
      "tensor([[ 0.0175,  0.0439, -0.0170,  0.1822, -0.1093, -0.4548, -0.0627]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "simple_mlp = SimpleMLP(input_dim=128, output_dim=7)\n",
    "print(simple_mlp)\n",
    "\n",
    "# input = torch.randn(1, 128)\n",
    "input = out\n",
    "out = simple_mlp(input)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pixel_encoder = PixelSetEncoder(input_dim=32, hidden_dim=64, output_dim=128)\n",
    "pixel_encoder = PixelSetEncoder(10, mlp1=[10, 32],\n",
    "                                pooling=\"mean_std\",\n",
    "                                mlp2=[64, 128])\n",
    "\n",
    "# transformer_encoder = TimeSeriesTransformer(feature_size=128)\n",
    "transformer_encoder = TimeSeriesTransformer(d_model=128)\n",
    "\n",
    "simple_mlp = SimpleMLP(input_dim=128, output_dim=7)\n",
    "\n",
    "# before adding mask\n",
    "# output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteModel(nn.Module):\n",
    "    def __init__(self, pixel_encoder, transformer_encoder, simple_mlp):\n",
    "        super(CompleteModel, self).__init__()\n",
    "        self.pixel_encoder = pixel_encoder\n",
    "        self.transformer_encoder = transformer_encoder\n",
    "        self.simple_mlp = simple_mlp\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        x = self.pixel_encoder(x, mask)  # torch.Size([8, 52, 128])\n",
    "        x = self.transformer_encoder(x)  # torch.Size([8, 128])\n",
    "        x = self.simple_mlp(x) # torch.Size([8, 7])\n",
    "        return x\n",
    "\n",
    "model = CompleteModel(pixel_encoder, transformer_encoder, simple_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δοκιμή Ολόκληρου Μοντέλου για είσοδο από Train Dataset με σταθερό πλήθος pixels = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 52, 10, 32])\n",
      "torch.Size([8])\n",
      "tensor([1, 0, 3, 1, 3, 1, 2, 2])\n",
      "torch.Size([8, 52, 32])\n",
      "\n",
      "torch.Size([8, 7])\n",
      "tensor([[-0.1727,  0.0470, -0.0699, -0.2945,  0.2160,  0.3588, -0.0322],\n",
      "        [-0.1711, -0.0410, -0.1523, -0.0953,  0.1853,  0.4787,  0.1776],\n",
      "        [-0.1915,  0.1050, -0.2368, -0.0611,  0.0703,  0.3974,  0.0005],\n",
      "        [-0.1398,  0.0335, -0.1930, -0.1196,  0.1740,  0.3175, -0.0538],\n",
      "        [-0.0662,  0.1261, -0.1321,  0.0670,  0.1845,  0.2747, -0.0215],\n",
      "        [-0.1758,  0.1575, -0.1197,  0.1476,  0.2580,  0.3085, -0.0586],\n",
      "        [-0.0270, -0.1638, -0.1319, -0.0501,  0.1577,  0.3406, -0.0881],\n",
      "        [-0.1372, -0.0958, -0.1480, -0.0944,  0.2829,  0.2929,  0.2447]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_dloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=pad_sequences_collate_fn,\n",
    "    # num_workers=4,\n",
    ")\n",
    "\n",
    "for batch in train_dloader:\n",
    "    input_tensor = batch[0]\n",
    "    labels = batch[1]\n",
    "    mask = batch[2]\n",
    "\n",
    "    print(input_tensor.shape)\n",
    "    print(labels.shape)\n",
    "    print(labels)\n",
    "    print(mask.shape)\n",
    "    print()\n",
    "\n",
    "    break\n",
    "\n",
    "# out = pixel_encoder(input_tensor, mask)\n",
    "# out = transformer_encoder(out)\n",
    "# out = simple_mlp(out)\n",
    "\n",
    "out = model(input_tensor, mask)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δοκιμή Ολόκληρου Μοντέλου για είσοδο από Val Dataset με μεταβλητό πλήθος pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 52, 10, 481])\n",
      "torch.Size([8])\n",
      "tensor([3, 2, 1, 2, 2, 1, 3, 2])\n",
      "torch.Size([8, 52, 481])\n",
      "\n",
      "torch.Size([8, 7])\n",
      "tensor([[-0.2786, -0.0051, -0.0927, -0.2523,  0.0856,  0.3379,  0.0127],\n",
      "        [-0.1772,  0.0250, -0.1623, -0.1980,  0.3534,  0.3684,  0.1281],\n",
      "        [-0.1173,  0.0588, -0.1673, -0.0185,  0.0347,  0.4545,  0.1378],\n",
      "        [-0.1696,  0.1196, -0.1855,  0.0449,  0.0979,  0.4006,  0.1338],\n",
      "        [-0.2636, -0.0120, -0.2221,  0.0861,  0.2160,  0.3663,  0.0974],\n",
      "        [-0.0561, -0.1237, -0.1480,  0.0695,  0.3556,  0.5386,  0.0969],\n",
      "        [-0.0051,  0.0267, -0.2549, -0.1177,  0.2214,  0.3052,  0.0976],\n",
      "        [-0.1395,  0.0360, -0.1237, -0.1323,  0.2120,  0.3655,  0.1363]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dloader:\n",
    "    input_tensor = batch[0]\n",
    "    labels = batch[1]\n",
    "    mask = batch[2]\n",
    "\n",
    "    print(input_tensor.shape)\n",
    "    print(labels.shape)\n",
    "    print(labels)\n",
    "    print(mask.shape)\n",
    "    print()\n",
    "\n",
    "    break\n",
    "\n",
    "# out = pixel_encoder(input_tensor, mask)\n",
    "# out = transformer_encoder(out)\n",
    "# out = simple_mlp(out)\n",
    "\n",
    "out = model(input_tensor, mask)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

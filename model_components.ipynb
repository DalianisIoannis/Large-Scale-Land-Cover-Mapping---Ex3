{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code comes from https://github.com/jnyborg/timematch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "# from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "import json\n",
    "from torchvision.transforms import transforms\n",
    "from utils import RandomSamplePixels, Normalize, ToTensor, PixelSetData,\\\n",
    "    split_dict_train_test, pad_sequences_collate_fn\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([52, 32, 10])\n",
      "torch.Size([52, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.norm = nn.BatchNorm1d(out_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = x.permute(0, 2, 1)\n",
    "\n",
    "        # x = (B, C) or (B, S, C)\n",
    "        x = self.linear(x)  # linear expect channels last\n",
    "        if x.dim() == 3:  \n",
    "            # BatchNorm1d expects channels first, move to (B, C, S)\n",
    "            x = self.norm(x.transpose(1, 2)).transpose(1, 2)\n",
    "        else:  # (B, C)\n",
    "            x = self.norm(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "# pixels_tmp = pixel_dataset[1901]['pixels'].permute(0, 2, 1)\n",
    "pixels_tmp = torch.randn(52, 10, 32).permute(0, 2, 1)\n",
    "print(\"input\", pixels_tmp.shape)\n",
    "\n",
    "ll = LinearLayer(10, 64)\n",
    "\n",
    "print(ll(pixels_tmp).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δοκιμή του LinearLayer με τυχαία διανύσματα όμως χωρίς μάσκες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LinearLayer(\n",
      "    (linear): Linear(in_features=10, out_features=32, bias=False)\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): LinearLayer(\n",
      "    (linear): Linear(in_features=64, out_features=128, bias=False)\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 52, 10, 32])\n",
      "torch.Size([52, 32, 10])\n",
      "torch.Size([52, 32, 32])\n",
      "torch.Size([52, 64])\n",
      "torch.Size([52, 128])\n",
      "torch.Size([1, 52, 128])\n"
     ]
    }
   ],
   "source": [
    "# mlp1_dim=[10, 32, 64]\n",
    "mlp1_dim=[10, 32]\n",
    "mlp2_dim=[64, 128]\n",
    "\n",
    "layers = []\n",
    "for i in range(len(mlp1_dim) - 1):\n",
    "    layers.append(LinearLayer(mlp1_dim[i], mlp1_dim[i + 1]))\n",
    "mlp1 = nn.Sequential(*layers)\n",
    "print(mlp1)\n",
    "\n",
    "layers = []\n",
    "for i in range(len(mlp2_dim) - 1):\n",
    "    layers.append(LinearLayer(mlp2_dim[i], mlp2_dim[i + 1]))\n",
    "mlp2 = nn.Sequential(*layers)\n",
    "print(mlp2)\n",
    "\n",
    "# out = pixel_dataset[1901]['pixels'].unsqueeze(0)\n",
    "out = torch.randn(52, 10, 32).unsqueeze(0)\n",
    "print(out.shape) # torch.Size([1, 52, 10, 32])\n",
    "\n",
    "batch, temp = out.shape[:2]\n",
    "# print(batch, temp) # 1 52\n",
    "\n",
    "out = out.view(batch * temp, *out.shape[2:]).transpose(1, 2)  # (B*T, S, C)\n",
    "print(out.shape) # torch.Size([52, 32, 10])\n",
    "\n",
    "out = mlp1(out).transpose(1, 2)\n",
    "print(out.shape) # torch.Size([52, 32, 32])\n",
    "\n",
    "out = torch.cat(\n",
    "            [out.mean(dim=-1), out.std(dim=-1)],\n",
    "            dim=1)\n",
    "print(out.shape) # torch.Size([52, 64])\n",
    "\n",
    "out = mlp2(out)\n",
    "print(out.shape) # torch.Size([52, 128])\n",
    "\n",
    "out = out.view(batch, temp, -1)\n",
    "print(out.shape) # torch.Size([1, 52, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mean(x, mask):\n",
    "    print(\"input of masked_mean unique\", x.unique())\n",
    "    print(\"input of masked_mean shape\", x.shape)\n",
    "    print(\"mask of masked_mean shape\", mask.shape)\n",
    "    print(\"mask of masked_mean uniques\", mask.unique())\n",
    "\n",
    "    # input of masked_mean shape torch.Size([416, 32, 32])\n",
    "    # mask of masked_mean shape torch.Size([416, 32])\n",
    "    \n",
    "    out = x.permute((1, 0, 2)) # torch.Size([32, 416, 32])\n",
    "    \n",
    "    out = out * mask # torch.Size([32, 416, 32])\n",
    "    # here every pixel gets to be zero\n",
    "    print(\"out = out * mask shape\", out.shape)\n",
    "    print(\"uniques of out = out * mask\", out.unique())\n",
    "    \n",
    "    out = out.sum(dim=-1) / mask.sum(dim=-1) # torch.Size([32, 416])\n",
    "    print(\"out = out.sum(dim=-1) / mask.sum(dim=-1) shape\", out.shape)\n",
    "    print(\"uniques here\", out.unique())\n",
    "    \n",
    "    out = out.permute((1, 0))\n",
    "    print(\"out of masked_mean unique\", out.unique())\n",
    "    print()\n",
    "    return out\n",
    "\n",
    "def masked_std(x, mask):\n",
    "    print(\"input of masked_std unique\", x.unique())\n",
    "    m = masked_mean(x, mask)\n",
    "\n",
    "    out = x.permute((2, 0, 1))\n",
    "    out = out - m\n",
    "    out = out.permute((2, 1, 0))\n",
    "\n",
    "    out = out * mask\n",
    "    d = mask.sum(dim=-1)\n",
    "    d[d == 1] = 2\n",
    "\n",
    "    out = (out ** 2).sum(dim=-1) / (d - 1)\n",
    "    out = torch.sqrt(out + 10e-32) # To ensure differentiability\n",
    "    out = out.permute(1, 0)\n",
    "    print(\"out of masked_std unique\", out.unique())\n",
    "    print()\n",
    "    return out\n",
    "\n",
    "pooling_methods = {\n",
    "    \"mean\": masked_mean,\n",
    "    \"std\": masked_std,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Οι extra χωρικές πληροφορίες δε χρειάζονται"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelSetEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        mlp1=[10, 32, 64],\n",
    "        pooling=\"mean_std\",\n",
    "        mlp2=[64, 128],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Pixel-set encoder.\n",
    "        Args:\n",
    "            input_dim (int): Number of channels of the input tensors\n",
    "            mlp1 (list):  Dimensions of the successive feature spaces of MLP1\n",
    "            pooling (str): Pixel-embedding pooling strategy, can be chosen in ('mean','std','max,'min')\n",
    "                or any underscore-separated combination thereof.\n",
    "            mlp2 (list): Dimensions of the successive feature spaces of MLP2\n",
    "            with_extra (bool): Whether additional pre-computed features are passed between the two MLPs\n",
    "            extra_size (int, optional): Number of channels of the additional features, if any.\n",
    "        \"\"\"\n",
    "\n",
    "        super(PixelSetEncoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.mlp1_dim = copy.deepcopy(mlp1)\n",
    "        self.mlp2_dim = copy.deepcopy(mlp2)\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.output_dim = (\n",
    "            input_dim * len(pooling.split(\"_\"))\n",
    "            if len(self.mlp2_dim) == 0\n",
    "            else self.mlp2_dim[-1]\n",
    "        )\n",
    "\n",
    "        # inter_dim = self.mlp1_dim[-1] * len(pooling.split(\"_\"))\n",
    "        # if self.with_extra:\n",
    "        #     inter_dim += self.extra_size\n",
    "        # assert input_dim == mlp1[0]\n",
    "        # assert inter_dim == mlp2[0]\n",
    "\n",
    "        # Feature extraction\n",
    "        layers = []\n",
    "        for i in range(len(self.mlp1_dim) - 1):\n",
    "            layers.append(LinearLayer(self.mlp1_dim[i], self.mlp1_dim[i + 1]))\n",
    "        self.mlp1 = nn.Sequential(*layers)\n",
    "\n",
    "        # MLP after pooling\n",
    "        layers = []\n",
    "        for i in range(len(self.mlp2_dim) - 1):\n",
    "            layers.append(LinearLayer(self.mlp2_dim[i], self.mlp2_dim[i + 1]))\n",
    "        self.mlp2 = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, pixels,\n",
    "                mask\n",
    "                ):\n",
    "        \"\"\"\n",
    "        The input of the PSE is a tuple of tensors as yielded by the PixelSetData class:\n",
    "          (Pixel-Set, Pixel-Mask) or ((Pixel-Set, Pixel-Mask), Extra-features)\n",
    "        Pixel-Set : Batch_size x (Sequence length) x Channel x Number of pixels\n",
    "        Pixel-Mask : Batch_size x (Sequence length) x Number of pixels\n",
    "        Extra-features : Batch_size x (Sequence length) x Number of features\n",
    "\n",
    "        If the input tensors have a temporal dimension, it will be combined with the batch dimension so that the\n",
    "        complete sequences are processed at once. Then the temporal dimension is separated back to produce a tensor of\n",
    "        shape Batch_size x Sequence length x Embedding dimension\n",
    "        \"\"\"\n",
    "        out = pixels\n",
    "\n",
    "        batch, temp = out.shape[:2]\n",
    "\n",
    "        out = out.view(batch * temp, *out.shape[2:]).transpose(1, 2)  # (B*T, S, C)\n",
    "        \n",
    "        mask = mask.view(batch * temp, -1)\n",
    "\n",
    "        out = self.mlp1(out).transpose(1, 2)\n",
    "\n",
    "        print(\"in pse out mask uniques\", mask.unique())\n",
    "        print(\"in pse out mask uniques type\", type(mask.unique()))\n",
    "        \n",
    "        # if not torch.equal(mask.unique(), torch.tensor([False])):\n",
    "        out = torch.cat(\n",
    "            [pooling_methods[n](out, mask) for n in self.pooling.split(\"_\")], dim=1\n",
    "        )\n",
    "        # else:\n",
    "        #     out = torch.cat(\n",
    "        #         [out.mean(dim=-1), out.std(dim=-1)],\n",
    "        #         dim=1\n",
    "        #     )\n",
    "\n",
    "        out = self.mlp2(out)\n",
    "        out = out.view(batch, temp, -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Είσοδος και έξοδος PSE πριν προστεθεί η μάσκα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input = pixel_dataset[1911]['pixels'].unsqueeze(0)\n",
    "# input = torch.randn(52, 10, 32).unsqueeze(0)\n",
    "# print(input.shape)\n",
    "# out = pixel_set_encoder(input)\n",
    "# print(out.shape) # torch.Size([1, 52, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δημιουργία Dataset και Dataloaders για τη δοκιμή του PSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4255\n",
      "7\n",
      "0 corn\n",
      "1 corn\n",
      "2 corn\n",
      "3 corn\n",
      "4 corn\n",
      "5 spring_barley\n",
      "6 corn\n",
      "\n",
      "corn 275\n",
      "spring_barley 1141\n",
      "meadow 1013\n",
      "winter_wheat 856\n",
      "winter_rapeseed 301\n",
      "winter_barley 352\n",
      "winter_rye 317\n"
     ]
    }
   ],
   "source": [
    "# labels_200 will contain the labels with more than 200 occurrences\n",
    "f_labels = open(r\"Exercise4\\timematch_data\\denmark\\32VNH\\2017\\meta\\labels_cleaned.json\")\n",
    "labels_200 = json.load(f_labels)\n",
    "\n",
    "print(len(labels_200))\n",
    "print(len(set(labels_200.values())))\n",
    "\n",
    "count = 0\n",
    "for lab in labels_200:\n",
    "    print(lab, labels_200[lab])\n",
    "    count += 1\n",
    "    if count == 7:\n",
    "        break\n",
    "\n",
    "labels_200_counter = Counter(labels_200.values())\n",
    "\n",
    "print()\n",
    "\n",
    "for lab in labels_200_counter:\n",
    "    print(lab, labels_200_counter[lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Οι παρακάτω αντιστοιχίσεις είναι διαφορετικές από του dataset_creation αλλά δεν πειράζει"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corn 0\n",
      "spring_barley 1\n",
      "meadow 2\n",
      "winter_wheat 3\n",
      "winter_rapeseed 4\n",
      "winter_barley 5\n",
      "winter_rye 6\n",
      "\n",
      "4255\n",
      "3400\n",
      "855\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = {cls: idx for idx, cls in enumerate(labels_200_counter)}\n",
    "for key, val in class_to_idx.items():\n",
    "    print(key, val)\n",
    "\n",
    "print()\n",
    "\n",
    "train_labels, val_labels = split_dict_train_test(labels_200, test_size=0.2)\n",
    "\n",
    "print(len(labels_200))\n",
    "print(len(train_labels))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\0.zarr', '0', 'corn')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1.zarr', '1', 'corn')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\10.zarr', '10', 'corn')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\100.zarr', '100', 'winter_rapeseed')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1000.zarr', '1000', 'spring_barley')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1001.zarr', '1001', 'winter_rye')\n",
      "3400\n",
      "\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1003.zarr', '1003', 'winter_barley')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1009.zarr', '1009', 'winter_barley')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1014.zarr', '1014', 'meadow')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1017.zarr', '1017', 'meadow')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1019.zarr', '1019', 'meadow')\n",
      "('Exercise4/timematch_data/denmark/32VNH/2017\\\\data\\\\1020.zarr', '1020', 'spring_barley')\n",
      "855\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([RandomSamplePixels(32), Normalize(), ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([Normalize(), ToTensor()])\n",
    "\n",
    "train_dataset = PixelSetData(\"Exercise4/timematch_data/denmark/32VNH/2017\",\n",
    "                             class_to_idx,\n",
    "                             train_labels,\n",
    "                             train_transform)\n",
    "print(len(train_dataset))\n",
    "print()\n",
    "val_dataset = PixelSetData(\"Exercise4/timematch_data/denmark/32VNH/2017\",\n",
    "                             class_to_idx,\n",
    "                             val_labels,\n",
    "                             test_transform)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "107\n",
      "torch.Size([8, 52, 10, 32])\n",
      "torch.Size([8])\n",
      "tensor([2, 1, 5, 1, 1, 5, 2, 3])\n",
      "torch.Size([8, 52, 32])\n",
      "[False]\n",
      "\n",
      "torch.Size([8, 52, 10, 2264])\n",
      "torch.Size([8])\n",
      "tensor([1, 1, 1, 3, 4, 6, 4, 2])\n",
      "torch.Size([8, 52, 2264])\n",
      "[False  True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=pad_sequences_collate_fn,\n",
    "    # num_workers=4,\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=pad_sequences_collate_fn,\n",
    ")\n",
    "\n",
    "print(len(train_dloader))\n",
    "print(len(val_dloader))\n",
    "\n",
    "for batch in train_dloader:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    print(batch[1])\n",
    "    print(batch[2].shape)\n",
    "    print(np.unique(batch[2]))\n",
    "    print()\n",
    "    break\n",
    "\n",
    "for batch in val_dloader:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    print(batch[1])\n",
    "    print(batch[2].shape)\n",
    "    print(np.unique(batch[2]))\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 52, 10, 32])\n",
      "torch.Size([8])\n",
      "tensor([6, 1, 2, 4, 2, 6, 3, 2])\n",
      "torch.Size([8, 52, 32])\n",
      "\n",
      "in pse out mask uniques tensor([False])\n",
      "in pse out mask uniques type <class 'torch.Tensor'>\n",
      "input of masked_mean unique tensor([0.0000e+00, 2.3799e-06, 3.4309e-06,  ..., 5.2826e+00, 5.2985e+00,\n",
      "        5.3041e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean shape torch.Size([416, 32, 32])\n",
      "mask of masked_mean shape torch.Size([416, 32])\n",
      "mask of masked_mean uniques tensor([False])\n",
      "out = out * mask shape torch.Size([32, 416, 32])\n",
      "uniques of out = out * mask tensor([0.], grad_fn=<Unique2Backward0>)\n",
      "out = out.sum(dim=-1) / mask.sum(dim=-1) shape torch.Size([32, 416])\n",
      "uniques here tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "out of masked_mean unique tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "input of masked_std unique tensor([0.0000e+00, 2.3799e-06, 3.4309e-06,  ..., 5.2826e+00, 5.2985e+00,\n",
      "        5.3041e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean unique tensor([0.0000e+00, 2.3799e-06, 3.4309e-06,  ..., 5.2826e+00, 5.2985e+00,\n",
      "        5.3041e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean shape torch.Size([416, 32, 32])\n",
      "mask of masked_mean shape torch.Size([416, 32])\n",
      "mask of masked_mean uniques tensor([False])\n",
      "out = out * mask shape torch.Size([32, 416, 32])\n",
      "uniques of out = out * mask tensor([0.], grad_fn=<Unique2Backward0>)\n",
      "out = out.sum(dim=-1) / mask.sum(dim=-1) shape torch.Size([32, 416])\n",
      "uniques here tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "out of masked_mean unique tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "out of masked_std unique tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "torch.Size([8, 52, 128])\n"
     ]
    }
   ],
   "source": [
    "pixel_set_encoder = PixelSetEncoder(10,\n",
    "                                    mlp1=[10, 32],\n",
    "                                    pooling=\"mean_std\",\n",
    "                                    mlp2=[64, 128])\n",
    "# print(pixel_set_encoder)\n",
    "print()\n",
    "\n",
    "for batch in train_dloader:\n",
    "    input_tensor = batch[0]\n",
    "    labels = batch[1]\n",
    "    mask = batch[2]\n",
    "\n",
    "    print(input_tensor.shape)\n",
    "    print(labels.shape)\n",
    "    print(labels)\n",
    "    print(mask.shape)\n",
    "    print()\n",
    "\n",
    "    break\n",
    "\n",
    "out = pixel_set_encoder(input_tensor, mask)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(out.detach().numpy()))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without collate_fn=pad_sequences_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 52, 10, 32])\n",
      "torch.Size([8])\n",
      "tensor([5, 1, 1, 1, 3, 1, 2, 5])\n",
      "torch.Size([8, 52, 32])\n",
      "\n",
      "in pse out mask uniques tensor([1.])\n",
      "in pse out mask uniques type <class 'torch.Tensor'>\n",
      "input of masked_mean unique tensor([0.0000e+00, 4.8964e-06, 2.7331e-05,  ..., 5.0042e+00, 5.0644e+00,\n",
      "        5.4251e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean shape torch.Size([416, 32, 32])\n",
      "mask of masked_mean shape torch.Size([416, 32])\n",
      "mask of masked_mean uniques tensor([1.])\n",
      "out = out * mask shape torch.Size([32, 416, 32])\n",
      "uniques of out = out * mask tensor([0.0000e+00, 4.8964e-06, 2.7331e-05,  ..., 5.0042e+00, 5.0644e+00,\n",
      "        5.4251e+00], grad_fn=<Unique2Backward0>)\n",
      "out = out.sum(dim=-1) / mask.sum(dim=-1) shape torch.Size([32, 416])\n",
      "uniques here tensor([0.0000e+00, 3.1566e-06, 2.2610e-05,  ..., 3.6695e+00, 3.6740e+00,\n",
      "        3.9598e+00], grad_fn=<Unique2Backward0>)\n",
      "out of masked_mean unique tensor([0.0000e+00, 3.1566e-06, 2.2610e-05,  ..., 3.6695e+00, 3.6740e+00,\n",
      "        3.9598e+00], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "input of masked_std unique tensor([0.0000e+00, 4.8964e-06, 2.7331e-05,  ..., 5.0042e+00, 5.0644e+00,\n",
      "        5.4251e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean unique tensor([0.0000e+00, 4.8964e-06, 2.7331e-05,  ..., 5.0042e+00, 5.0644e+00,\n",
      "        5.4251e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean shape torch.Size([416, 32, 32])\n",
      "mask of masked_mean shape torch.Size([416, 32])\n",
      "mask of masked_mean uniques tensor([1.])\n",
      "out = out * mask shape torch.Size([32, 416, 32])\n",
      "uniques of out = out * mask tensor([0.0000e+00, 4.8964e-06, 2.7331e-05,  ..., 5.0042e+00, 5.0644e+00,\n",
      "        5.4251e+00], grad_fn=<Unique2Backward0>)\n",
      "out = out.sum(dim=-1) / mask.sum(dim=-1) shape torch.Size([32, 416])\n",
      "uniques here tensor([0.0000e+00, 3.1566e-06, 2.2610e-05,  ..., 3.6695e+00, 3.6740e+00,\n",
      "        3.9598e+00], grad_fn=<Unique2Backward0>)\n",
      "out of masked_mean unique tensor([0.0000e+00, 3.1566e-06, 2.2610e-05,  ..., 3.6695e+00, 3.6740e+00,\n",
      "        3.9598e+00], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "out of masked_std unique tensor([3.1623e-16, 6.0558e-08, 1.2112e-07,  ..., 1.3762e+00, 1.5066e+00,\n",
      "        1.5618e+00], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "torch.Size([8, 52, 128])\n"
     ]
    }
   ],
   "source": [
    "train_dloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    # collate_fn=pad_sequences_collate_fn,\n",
    "    # num_workers=4,\n",
    ")\n",
    "\n",
    "print(len(train_dloader))\n",
    "\n",
    "for batch in train_dloader:\n",
    "    input_tensor = batch[\"pixels\"]\n",
    "    labels = batch[\"label_idx\"]\n",
    "    mask = batch[\"valid_pixels\"]\n",
    "\n",
    "    print(input_tensor.shape)\n",
    "    print(labels.shape)\n",
    "    print(labels)\n",
    "    print(mask.shape)\n",
    "    print()\n",
    "\n",
    "    break\n",
    "\n",
    "out = pixel_set_encoder(input_tensor, mask)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 5.2034855e-05 7.1287155e-05 ... 5.2809896e+00 5.4021277e+00\n",
      " 5.7293777e+00]\n",
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 1.2681, 0.4686, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.5516, 0.7058, 0.0000],\n",
      "         [2.9054, 0.5577, 3.4015,  ..., 0.0000, 0.0000, 3.1386],\n",
      "         ...,\n",
      "         [1.3263, 0.6960, 2.2402,  ..., 0.0000, 0.0000, 2.0096],\n",
      "         [0.4801, 0.7719, 0.7552,  ..., 0.0000, 0.2659, 0.9189],\n",
      "         [0.0000, 0.1298, 0.0000,  ..., 1.2440, 0.3603, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 1.1416, 0.7593, 0.0000],\n",
      "         [1.4487, 0.0000, 1.1900,  ..., 0.0000, 0.0000, 1.2956],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.5114, 0.5966, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.1089, 0.6143, 0.0000],\n",
      "         [0.4578, 0.4223, 0.6176,  ..., 0.0000, 0.0000, 0.7925],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.6478, 0.9148, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 1.2068, 0.5327, 0.0000],\n",
      "         [0.0000, 0.0000, 0.5610,  ..., 0.7883, 0.1827, 0.0000],\n",
      "         [1.3757, 0.9353, 2.7006,  ..., 0.0000, 0.0000, 2.2637],\n",
      "         ...,\n",
      "         [0.8372, 0.5860, 1.1225,  ..., 0.3375, 0.2903, 1.1180],\n",
      "         [0.0000, 0.6834, 0.1837,  ..., 0.4089, 1.4466, 0.0214],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.9401, 0.6998, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.9013, 0.9346, 0.0000],\n",
      "         [0.0000, 0.6807, 0.3536,  ..., 0.0000, 1.2488, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.4406, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.4406, 0.0000, 0.0000],\n",
      "         [1.9446, 0.3647, 1.4147,  ..., 0.0000, 0.0000, 1.9199],\n",
      "         [0.0543, 1.0153, 0.7569,  ..., 0.0000, 0.3152, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 1.3420, 0.5878, 0.0000],\n",
      "         [0.5534, 0.0000, 0.5927,  ..., 0.3484, 0.1346, 0.3169],\n",
      "         [1.6449, 0.8771, 2.4758,  ..., 0.0000, 0.0000, 2.5977],\n",
      "         ...,\n",
      "         [0.0000, 0.2178, 0.0000,  ..., 1.3492, 0.8007, 0.0000],\n",
      "         [0.0000, 0.7959, 0.3462,  ..., 0.3437, 1.4182, 0.0890],\n",
      "         [0.8187, 1.0080, 0.6325,  ..., 0.0000, 0.0000, 0.5304]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 1.0103, 0.7382, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.8693, 0.4848, 0.0000],\n",
      "         [2.5253, 0.0000, 1.6694,  ..., 0.0000, 0.0000, 2.2169],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.3072, 0.8168, 0.0000],\n",
      "         [0.0000, 0.0788, 0.0000,  ..., 0.6537, 1.0839, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.5653, 0.3970, 0.0000]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(out.detach().numpy()))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dloader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=8,\n",
    "#     shuffle=True,\n",
    "#     # collate_fn=pad_sequences_collate_fn,\n",
    "#     # num_workers=4,\n",
    "# )\n",
    "\n",
    "# print(len(val_dloader))\n",
    "\n",
    "# for batch in val_dloader:\n",
    "#     input_tensor = batch[\"pixels\"]\n",
    "#     labels = batch[\"label_idx\"]\n",
    "#     mask = batch[\"valid_pixels\"]\n",
    "\n",
    "#     print(input_tensor.shape)\n",
    "#     print(labels.shape)\n",
    "#     print(labels)\n",
    "#     print(mask.shape)\n",
    "#     print()\n",
    "\n",
    "#     break\n",
    "\n",
    "# out = pixel_set_encoder(input_tensor, mask)\n",
    "\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 52, 128])\n"
     ]
    }
   ],
   "source": [
    "# can also check Tsironis\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                #  dropout: float = 0.1,\n",
    "                #  max_len: int = 5000\n",
    "                 max_len: int = 52\n",
    "                 ):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "            )\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "pe = PositionalEncoding(128)\n",
    "\n",
    "input = torch.randn(1, 52, 128)\n",
    "out = pe(input)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# class TimeSeriesTransformer(nn.Module):\n",
    "#     def __init__(self,\n",
    "#                  feature_size,\n",
    "#                  num_classes: int = 7,\n",
    "#                  num_layers=3, num_heads=8,\n",
    "#                 #  hidden_dim=512, dropout=0.1\n",
    "#                  ):\n",
    "#         super(TimeSeriesTransformer, self).__init__()\n",
    "        \n",
    "#         self.pos_encoder = PositionalEncoding(feature_size)\n",
    "#         self.encoder_layers = TransformerEncoderLayer(\n",
    "#             d_model=feature_size, nhead=num_heads,\n",
    "#             # dim_feedforward=hidden_dim,\n",
    "#             # dropout=dropout,\n",
    "#             batch_first=True\n",
    "#             )\n",
    "#         self.transformer_encoder = TransformerEncoder(self.encoder_layers, num_layers)\n",
    "        \n",
    "#         self.classification_token = nn.Parameter(torch.zeros(1, 1, feature_size),\n",
    "#                                                  requires_grad=True\n",
    "#                                                  )\n",
    "#         self.fc = nn.Linear(feature_size, num_classes)  # Adjust the output dimension as needed\n",
    "        \n",
    "#     def forward(self,\n",
    "#                 x: torch.Tensor,\n",
    "#                 ) -> torch.Tensor:\n",
    "#         \"\"\"\n",
    "#         Arguments:\n",
    "#             x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "#         \"\"\"\n",
    "#         batch_size, seq_len, feature_size = x.size()\n",
    "        \n",
    "#         x = self.pos_encoder(x)  # BS x T x d_model\n",
    "\n",
    "#         # Add classification token\n",
    "#         cls_tokens = self.classification_token.expand(batch_size, -1, -1)\n",
    "\n",
    "#         x = torch.cat((cls_tokens, x), dim=1)  # [batch_size, seq_len + 1, feature_size]\n",
    "        \n",
    "#         # # Add positional encoding and permute for Transformer [seq_len + 1, batch_size, feature_size]\n",
    "#         # x = self.pos_encoder(x.permute(1, 0, 2))\n",
    "\n",
    "#         x = self.transformer_encoder(x)  # Pass through the transformer encoder\n",
    "#         # x = x[0, :, :]  # Extract the classification token output\n",
    "\n",
    "#         # from Tsironis\n",
    "#         # x = x[:, 0, :]  # BS x d_model\n",
    "        \n",
    "#         x = self.fc(x)  # Final classification layer\n",
    "#         # return x.squeeze()  # Adjust based on the output needs\n",
    "#         return x\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                #  num_classes: int,\n",
    "                 d_model: int = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=nn.TransformerEncoderLayer(\n",
    "                d_model=d_model, nhead=8, batch_first=True\n",
    "            ),\n",
    "            num_layers=3,\n",
    "        )\n",
    "\n",
    "        self.cls_tkn = nn.Parameter(torch.rand(1, 1, d_model), requires_grad=True)\n",
    "\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(d_model, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, num_classes),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        # BS x T x 512\n",
    "        x = self.pos_emb(x)  # BS x T x d_model\n",
    "\n",
    "        cls_tkn = self.cls_tkn.expand(x.shape[0], -1, -1)  # BS x 1 x d_model\n",
    "        x = torch.cat([cls_tkn, x], dim=1)  # BS x (T+1) x d_model\n",
    "\n",
    "        x = self.encoder(x)  # BS x (T+1) x d_model\n",
    "\n",
    "        x = x[:, 0, :]  # BS x d_model\n",
    "        \n",
    "        # return self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# time_series_transformer = TimeSeriesTransformer(feature_size=128)\n",
    "time_series_transformer = TimeSeriesTransformer(\n",
    "    # num_classes=7,\n",
    "    d_model=128)\n",
    "# print(time_series_transformer)\n",
    "\n",
    "input = torch.randn(1, 52, 128)\n",
    "out = time_series_transformer(input)\n",
    "print(\"Output shape: \", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n",
      "tensor([[-0.2005,  0.1235, -0.0537, -0.1899, -0.0502,  0.0364,  0.1819]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim: int = 7):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "simple_mlp = SimpleMLP(input_dim=128, output_dim=7)\n",
    "# print(simple_mlp)\n",
    "\n",
    "# input = torch.randn(1, 128)\n",
    "input = out\n",
    "out = simple_mlp(input)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CompleteModel(nn.Module):\n",
    "#     def __init__(self, pixel_encoder, transformer_encoder):\n",
    "#         super(CompleteModel, self).__init__()\n",
    "#         self.pixel_encoder = pixel_encoder\n",
    "#         self.transformer_encoder = transformer_encoder\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.pixel_encoder(x)  # Shape: [batch_size, seq_len, feature_size]\n",
    "#         x = self.transformer_encoder(x)  # Shape: [batch_size]\n",
    "#         return x\n",
    "\n",
    "# input_tensor = torch.randn(1, 52, 10, 32)  # Example input tensor\n",
    "\n",
    "# # pixel_encoder = PixelSetEncoder(input_dim=32, hidden_dim=64, output_dim=128)\n",
    "pixel_encoder = PixelSetEncoder(10,\n",
    "                                mlp1=[10, 32],\n",
    "                                pooling=\"mean_std\",\n",
    "                                mlp2=[64, 128])\n",
    "# transformer_encoder = TimeSeriesTransformer(feature_size=128)\n",
    "transformer_encoder = TimeSeriesTransformer(d_model=128)\n",
    "\n",
    "simple_mlp = SimpleMLP(input_dim=128, output_dim=7)\n",
    "\n",
    "# model = CompleteModel(pixel_encoder, transformer_encoder)\n",
    "\n",
    "# output = model(input_tensor)\n",
    "# print(output.shape)  # Adjust based on the final classification layer output dimension\n",
    "\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 52, 10, 32])\n",
      "torch.Size([8])\n",
      "tensor([3, 1, 3, 2, 1, 1, 3, 3])\n",
      "torch.Size([8, 52, 32])\n",
      "\n",
      "in pse out mask uniques tensor([False])\n",
      "in pse out mask uniques type <class 'torch.Tensor'>\n",
      "input of masked_mean unique tensor([0.0000e+00, 1.1681e-06, 7.1629e-06,  ..., 5.2140e+00, 5.2468e+00,\n",
      "        5.3344e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean shape torch.Size([416, 32, 32])\n",
      "mask of masked_mean shape torch.Size([416, 32])\n",
      "mask of masked_mean uniques tensor([False])\n",
      "out = out * mask shape torch.Size([32, 416, 32])\n",
      "uniques of out = out * mask tensor([0.], grad_fn=<Unique2Backward0>)\n",
      "out = out.sum(dim=-1) / mask.sum(dim=-1) shape torch.Size([32, 416])\n",
      "uniques here tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "out of masked_mean unique tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "input of masked_std unique tensor([0.0000e+00, 1.1681e-06, 7.1629e-06,  ..., 5.2140e+00, 5.2468e+00,\n",
      "        5.3344e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean unique tensor([0.0000e+00, 1.1681e-06, 7.1629e-06,  ..., 5.2140e+00, 5.2468e+00,\n",
      "        5.3344e+00], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean shape torch.Size([416, 32, 32])\n",
      "mask of masked_mean shape torch.Size([416, 32])\n",
      "mask of masked_mean uniques tensor([False])\n",
      "out = out * mask shape torch.Size([32, 416, 32])\n",
      "uniques of out = out * mask tensor([0.], grad_fn=<Unique2Backward0>)\n",
      "out = out.sum(dim=-1) / mask.sum(dim=-1) shape torch.Size([32, 416])\n",
      "uniques here tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "out of masked_mean unique tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "out of masked_std unique tensor([nan, nan, nan,  ..., nan, nan, nan], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "torch.Size([8, 52, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 7])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_dloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=pad_sequences_collate_fn,\n",
    "    # num_workers=4,\n",
    ")\n",
    "\n",
    "for batch in train_dloader:\n",
    "    input_tensor = batch[0]\n",
    "    labels = batch[1]\n",
    "    mask = batch[2]\n",
    "\n",
    "    print(input_tensor.shape)\n",
    "    print(labels.shape)\n",
    "    print(labels)\n",
    "    print(mask.shape)\n",
    "    print()\n",
    "\n",
    "    break\n",
    "\n",
    "out = pixel_encoder(input_tensor, mask)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "out = transformer_encoder(out)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "# print(out)\n",
    "\n",
    "out = simple_mlp(out)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 52, 10, 2830])\n",
      "torch.Size([8])\n",
      "tensor([6, 4, 4, 6, 3, 2, 2, 3])\n",
      "torch.Size([8, 52, 2830])\n",
      "\n",
      "in pse out mask uniques tensor([False,  True])\n",
      "in pse out mask uniques type <class 'torch.Tensor'>\n",
      "input of masked_mean unique tensor([0.0000e+00, 1.3078e-07, 5.4485e-07,  ..., 1.0073e+01, 1.0092e+01,\n",
      "        1.0109e+01], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean shape torch.Size([416, 32, 2830])\n",
      "mask of masked_mean shape torch.Size([416, 2830])\n",
      "mask of masked_mean uniques tensor([False,  True])\n",
      "out = out * mask shape torch.Size([32, 416, 2830])\n",
      "uniques of out = out * mask tensor([0.0000, 0.0134, 0.0611, 0.2291, 0.2377, 0.2890, 0.3258, 0.4007, 0.4104,\n",
      "        0.4353, 0.4621, 0.4664, 0.4667, 0.4691, 0.4722, 0.4752, 0.4775],\n",
      "       grad_fn=<Unique2Backward0>)\n",
      "out = out.sum(dim=-1) / mask.sum(dim=-1) shape torch.Size([32, 416])\n",
      "uniques here tensor([0.0000, 0.0134, 0.0134,  ...,    nan,    nan,    nan],\n",
      "       grad_fn=<Unique2Backward0>)\n",
      "out of masked_mean unique tensor([0.0000, 0.0134, 0.0134,  ...,    nan,    nan,    nan],\n",
      "       grad_fn=<Unique2Backward0>)\n",
      "\n",
      "input of masked_std unique tensor([0.0000e+00, 1.3078e-07, 5.4485e-07,  ..., 1.0073e+01, 1.0092e+01,\n",
      "        1.0109e+01], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean unique tensor([0.0000e+00, 1.3078e-07, 5.4485e-07,  ..., 1.0073e+01, 1.0092e+01,\n",
      "        1.0109e+01], grad_fn=<Unique2Backward0>)\n",
      "input of masked_mean shape torch.Size([416, 32, 2830])\n",
      "mask of masked_mean shape torch.Size([416, 2830])\n",
      "mask of masked_mean uniques tensor([False,  True])\n",
      "out = out * mask shape torch.Size([32, 416, 2830])\n",
      "uniques of out = out * mask tensor([0.0000, 0.0134, 0.0611, 0.2291, 0.2377, 0.2890, 0.3258, 0.4007, 0.4104,\n",
      "        0.4353, 0.4621, 0.4664, 0.4667, 0.4691, 0.4722, 0.4752, 0.4775],\n",
      "       grad_fn=<Unique2Backward0>)\n",
      "out = out.sum(dim=-1) / mask.sum(dim=-1) shape torch.Size([32, 416])\n",
      "uniques here tensor([0.0000, 0.0134, 0.0134,  ...,    nan,    nan,    nan],\n",
      "       grad_fn=<Unique2Backward0>)\n",
      "out of masked_mean unique tensor([0.0000, 0.0134, 0.0134,  ...,    nan,    nan,    nan],\n",
      "       grad_fn=<Unique2Backward0>)\n",
      "\n",
      "out of masked_std unique tensor([3.1623e-16, 9.3150e-10, 9.3152e-10,  ...,        nan,        nan,\n",
      "               nan], grad_fn=<Unique2Backward0>)\n",
      "\n",
      "torch.Size([8, 52, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 7])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dloader:\n",
    "    input_tensor = batch[0]\n",
    "    labels = batch[1]\n",
    "    mask = batch[2]\n",
    "\n",
    "    print(input_tensor.shape)\n",
    "    print(labels.shape)\n",
    "    print(labels)\n",
    "    print(mask.shape)\n",
    "    print()\n",
    "\n",
    "    break\n",
    "\n",
    "out = pixel_encoder(input_tensor, mask)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "out = transformer_encoder(out)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "# print(out)\n",
    "\n",
    "out = simple_mlp(out)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
